{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-us-patent-phrase-maching-roberta-baseline.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN9W5qZLojEEwKjyWWqY1yM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/kaggle-competition-projects/blob/master/us-patent-phrase-competition/02_us_patent_phrase_maching_roberta_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8mZMCFWo5_K"
      },
      "source": [
        "##US Patent Phrase to Phrase maching - Roberta -baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgpmDaAaqFGq"
      },
      "source": [
        "In this dataset, you are presented pairs of phrases (an anchor and a target phrase) and asked to rate how similar they are on a scale from 0 (not at all similar) to 1 (identical in meaning). This challenge differs from a standard semantic similarity task in that similarity has been scored here within a patent's context, specifically its CPC classification (version 2021.05), which indicates the subject to which the patent relates. For example, while the phrases \"bird\" and \"Cape Cod\" may have low semantic similarity in normal language, the likeness of their meaning is much closer if considered in the context of \"house\".\n",
        "\n",
        "This is a code competition, in which you will submit code that will be run against an unseen test set. The unseen test set contains approximately 12k pairs of phrases. A small public test set has been provided for testing purposes, but is not used in scoring.\n",
        "\n",
        "Information on the meaning of CPC codes may be found on the USPTO website. The CPC version 2021.05 can be found on the CPC archive website.\n",
        "\n",
        "**Score meanings**\n",
        "\n",
        "The scores are in the 0-1 range with increments of 0.25 with the following meanings:\n",
        "\n",
        "* **1.0 - Very close match**. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”).\n",
        "* **0.75 - Close synonym**, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n",
        "* **0.5 - Synonyms** which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n",
        "* **0.25 - Somewhat related**, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n",
        "* **0.0 - Unrelated**.\n",
        "\n",
        "**Columns**\n",
        "\n",
        "* **id** - a unique identifier for a pair of phrases\n",
        "* **anchor** - the first phrase\n",
        "* **target** - the second phrase\n",
        "* **context** - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n",
        "* **score** - the similarity. This is sourced from a combination of one or more manual expert ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l49aSiS6qJjk"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "pip -q install transformers\n",
        "pip -q install datasets"
      ],
      "metadata": {
        "id": "uEY3JhlK3fzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnTq4mih60yh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from termcolor import colored\n",
        "\n",
        "import datasets,transformers\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "colors = [\"#A2A21C\", \"#CBCB1A\", \"#E1E10B\", \"#F6F605\", \"#838305\"]"
      ],
      "metadata": {
        "id": "Yy52_nJY36qP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFVevHPKrNq3"
      },
      "source": [
        "Let's load dataset from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ-9t0vZrTch"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() # upload kaggle.json file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO7P_w-YrbCF"
      },
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "mv kaggle.json ~/.kaggle/\n",
        "ls ~/.kaggle\n",
        "chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# download dataset from kaggle> URL: https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching\n",
        "kaggle competitions download -c us-patent-phrase-to-phrase-matching\n",
        "unzip -qq us-patent-phrase-to-phrase-matching.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define config."
      ],
      "metadata": {
        "id": "IDmN2yng6FUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "  input_path = '/us-patent-phrase-to-phrase-matching/'\n",
        "  model_path = '/roberta-base'\n",
        "  model = 'roberta-base'\n",
        "  \n",
        "  learning_rate = 2e-5\n",
        "  weight_decay = 0.01\n",
        "  \n",
        "  epochs = 5\n",
        "  batch_size = 32"
      ],
      "metadata": {
        "id": "U2TV58Hg5G8o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sections = {\n",
        " 'A': 'Human Necessities',\n",
        " 'B': 'Operations and Transport',\n",
        " 'C': 'Chemistry and Metallurgy',\n",
        " 'D': 'Textiles',\n",
        " 'E': 'Fixed Constructions',\n",
        " 'F': 'Mechanical Engineering',\n",
        " 'G': 'Physics',\n",
        " 'H': 'Electricity',\n",
        " 'Y': 'Emerging Cross-Sectional Technologies'\n",
        "}"
      ],
      "metadata": {
        "id": "lpcAGXYW5Zbf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load model."
      ],
      "metadata": {
        "id": "otrrGEdY6Kv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(config.model, num_labels=1)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model)"
      ],
      "metadata": {
        "id": "b1_H87Eg6J27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAGIwwJtsoGH"
      },
      "source": [
        "## Loading dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wduwoi7vsX1g"
      },
      "source": [
        "df_train = datasets.Dataset.from_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcvpecCMs9RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13b42cd-f9df-4dd8-96ff-afbdea52c0bb"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'anchor', 'target', 'context', 'score'],\n",
              "    num_rows: 36473\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = datasets.Dataset.from_csv('test.csv')"
      ],
      "metadata": {
        "id": "guIRR0ZH1llA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "ZLNDBQ56467H",
        "outputId": "de493623-2c7f-490b-fd32-7f7930e65f1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'anchor', 'target', 'context'],\n",
              "    num_rows: 36\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOU1FSvO5V58"
      },
      "source": [
        "## Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(ds, eval=False):\n",
        "  context = ds[\"context\"][0]\n",
        "  prefix = sections[context]\n",
        "  anchor = ds[\"anchor\"]\n",
        "\n",
        "  return {\n",
        "      **tokenizer(prefix + anchor, ds[\"target\"], ), \"label\": ds[\"score\"] \n",
        "  }"
      ],
      "metadata": {
        "id": "yAE9ifUh5lBb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_ds = df_train.map(preprocess, remove_columns=[\"id\", \"anchor\", \"target\", \"context\", \"score\"])"
      ],
      "metadata": {
        "id": "77C_vanm-_wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_ds[100]"
      ],
      "metadata": {
        "id": "cFpZHU5d_b4-",
        "outputId": "17110d50-3415-438a-dd4c-3c599d01dd1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [0, 48176, 37276, 2485, 873, 21113, 737, 2, 2, 873, 21113, 2],\n",
              " 'label': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_ds = encoded_ds.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "VcnFzh8V_gkn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training model"
      ],
      "metadata": {
        "id": "5BTwZheYAxli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "81jLW0dvA0Da"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}