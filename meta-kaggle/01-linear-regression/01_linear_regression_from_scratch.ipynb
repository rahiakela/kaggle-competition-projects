{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMjjjgHgL7EtLBlMGRwJPVs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/kaggle-competition-projects/blob/master/meta-kaggle/01-linear-regression/01_linear_regression_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear Regression from scratch"
      ],
      "metadata": {
        "id": "QQFu_qQyjJDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "5r3EGk4ljJ36"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors\n",
        "x = torch.tensor(3.0)\n",
        "w = torch.tensor(4.0, requires_grad=True)\n",
        "b = torch.tensor(5.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "IXUbtTEBjS5d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can combine tensors with the usual arithmetic operations."
      ],
      "metadata": {
        "id": "_7PZ9M7KkkUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithmetic operations\n",
        "y = w * x + b\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD0mP_g3jkvE",
        "outputId": "83333ac7-61d8-4f00-8387-6f2cd9bfa721"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(17., grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What makes PyTorch special, is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. `w` and `b`."
      ],
      "metadata": {
        "id": "_9uTMvyOkg5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute gradients\n",
        "y.backward()"
      ],
      "metadata": {
        "id": "Mw4l9ssAjwrL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display gradients\n",
        "print(f\"dy/dw: {w.grad}\")\n",
        "print(f\"dy/db: {b.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf5vpIiSjyxI",
        "outputId": "83d62aff-79f1-49a3-ffc7-91b5e592b534"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dw: 3.0\n",
            "dy/db: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem Statement"
      ],
      "metadata": {
        "id": "901FJEDUkJ2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll create a model that predicts crop yeilds for apples and oranges (*target variables*) by looking at the average temperature, rainfall and humidity (*input variables or features*) in a region. Here's the training data:\n",
        "\n",
        "<img src=\"https://i.imgur.com/lBguUV9.png\" width=\"500\" />\n",
        "\n",
        "In a **linear regression** model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
        "\n",
        "```\n",
        "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yeild_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "Visually, it means that the yield of apples is a linear or planar function of the temperature, rainfall & humidity.\n",
        "\n",
        "<img src=\"https://i.imgur.com/mtkR2lB.png\" width=\"540\" >\n",
        "\n",
        "\n",
        "**Our objective**: Find a suitable set of *weights* and *biases* using the training data, to make accurate predictions."
      ],
      "metadata": {
        "id": "q57-IkAekLaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Data"
      ],
      "metadata": {
        "id": "17vZRf8Qk5Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training data can be represented using 2 matrices (inputs and targets), each with one row per observation and one column per variable."
      ],
      "metadata": {
        "id": "v90SX3Mlk50w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([\n",
        "    [73, 67, 43],\n",
        "    [91, 88, 64],\n",
        "    [87, 134, 58],\n",
        "    [102, 43, 37],\n",
        "    [69, 96, 70]\n",
        "], dtype=\"float32\")"
      ],
      "metadata": {
        "id": "-NtruM1tkCdL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([\n",
        "    [56, 70],\n",
        "    [81, 101],\n",
        "    [119, 133],\n",
        "    [22, 37],\n",
        "    [103, 119]\n",
        "], dtype=\"float32\")"
      ],
      "metadata": {
        "id": "FgUnK13slYwU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we build a model, we need to convert inputs and targets to PyTorch tensors."
      ],
      "metadata": {
        "id": "S81KgKIslmHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert inputs and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-33GYHallCT",
        "outputId": "17d290f6-2d1e-4741-973b-b09508833fff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear Regression Model"
      ],
      "metadata": {
        "id": "VgE5zqSOl8K6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *weights* and *biases* can also be represented as matrices, initialized with random values. The first row of `w` and the first element of `b` are use to predict the first target variable i.e. yield for apples, and similarly the second for oranges."
      ],
      "metadata": {
        "id": "b5c7RVVcl9l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "VmWkh10UmDRu",
        "outputId": "4cdc76cb-99df-4129-ea35-ec37e6bb75c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.3306,  0.9132,  1.4294],\n",
            "        [-0.8502,  1.2604,  0.3483]], requires_grad=True)\n",
            "tensor([ 1.1598, -1.0976], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *model* is simply a function that performs a matrix multiplication of the input `x` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
        "\n",
        "$$\n",
        "\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\left[ \\begin{array}{cc}\n",
        "73 & 67 & 43 \\\\\n",
        "91 & 88 & 64 \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "69 & 96 & 70\n",
        "\\end{array} \\right]\n",
        "%\n",
        "\\times\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "w_{11} & w_{21} \\\\\n",
        "w_{12} & w_{22} \\\\\n",
        "w_{13} & w_{23}\n",
        "\\end{array} \\right]\n",
        "%\n",
        "+\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "b_{1} & b_{2} \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\end{array} \\right]\n",
        "$$"
      ],
      "metadata": {
        "id": "EBFWS1Yt19xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "BbyAWC4b1KGJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The matrix obtained by passing the input data to the model is a set of predictions for the target variables."
      ],
      "metadata": {
        "id": "Be9SU0uG2T48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "id": "lpk5I21a2UVT",
        "outputId": "98aad347-a528-42df-f338-3c7705393d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 26.6747,  36.2606],\n",
            "        [ 51.9182,  54.7395],\n",
            "        [ 90.6727, 114.0314],\n",
            "        [-42.4062, -20.7368],\n",
            "        [ 97.0734,  85.6181]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with targets\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "5CSwni362dDb",
        "outputId": "392884fd-a334-4c9b-88a7-bc15b5b055d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we've started with random weights and biases, the model does not a very good job of predicting the target varaibles."
      ],
      "metadata": {
        "id": "eXeVjGV72xFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss Function"
      ],
      "metadata": {
        "id": "BjDY2zEu2xjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compare the predictions with the actual targets, using the following method:\n",
        "* Calculate the difference between the two matrices (`preds` and `targets`).\n",
        "* Square all elements of the difference matrix to remove negative values.\n",
        "* Calculate the average of the elements in the resulting matrix.\n",
        "\n",
        "The result is a single number, known as the **mean squared error** (MSE)."
      ],
      "metadata": {
        "id": "dMF5zTAH21VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE loss\n",
        "def mse(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "k2yHl6Qt28_s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "sN16xe8w5KZ2",
        "outputId": "f9d27100-2f31-49c8-9963-68e3c0b55bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1477.7517, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting number is called the **loss**, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model."
      ],
      "metadata": {
        "id": "FMTXY-o15aL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compute Gradients"
      ],
      "metadata": {
        "id": "k1p_6tX15bdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With PyTorch, we can automatically compute the gradient or derivative of the `loss` w.r.t. to the weights and biases, because they have `requires_grad` set to `True`."
      ],
      "metadata": {
        "id": "x3WwO20b5eCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute gradients\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "s25HoyCq5gF2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gradients are stored in the `.grad` property of the respective tensors."
      ],
      "metadata": {
        "id": "ok-F9Tvu5xRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradients for weights\n",
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "id": "-qS20vxN5xqj",
        "outputId": "0e15ac5b-d1e8-4a8d-f696-dc4502bed350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.3306,  0.9132,  1.4294],\n",
            "        [-0.8502,  1.2604,  0.3483]], requires_grad=True)\n",
            "tensor([[-2846.0066, -2331.6536, -1512.6191],\n",
            "        [-3303.0898, -2912.1199, -1996.9275]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradients for bias\n",
        "print(b)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "Kj3kuyT-535w",
        "outputId": "7e8e9d8d-8488-4ff0-e8f1-6477ee1b642d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.1598, -1.0976], requires_grad=True)\n",
            "tensor([-31.4134, -38.0174])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A key insight from calculus is that the gradient indicates the rate of change of the loss, or the slope of the loss function w.r.t. the weights and biases.\n",
        "\n",
        "* If a gradient element is **postive**,\n",
        "    * **increasing** the element's value slightly will **increase** the loss.\n",
        "    * **decreasing** the element's value slightly will **decrease** the loss.\n",
        "\n",
        "<img src=\"https://i.imgur.com/2H4INoV.png\" width=\"400\" />\n",
        "\n",
        "\n",
        "\n",
        "* If a gradient element is **negative**,\n",
        "    * **increasing** the element's value slightly will **decrease** the loss.\n",
        "    * **decreasing** the element's value slightly will **increase** the loss.\n",
        "    \n",
        "<img src=\"https://i.imgur.com/h7E2uAv.png\" width=\"400\" />    \n",
        "\n",
        "The increase or decrease is proportional to the value of the gradient.\n",
        "\n",
        "Finally, we'll reset the gradients to zero before moving forward, because PyTorch accumulates gradients."
      ],
      "metadata": {
        "id": "Jlp4D0DS6YFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "VbyjaidE6Ygt",
        "outputId": "2f52f677-f4f9-4b36-edcb-60903a5d1ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adjust Gradients"
      ],
      "metadata": {
        "id": "Z2iFDAVb7Kmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll reduce the loss and improve our model using the gradient descent algorithm, which has the following steps:\n",
        "\n",
        "1. Generate predictions\n",
        "2. Calculate the loss\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "5. Reset the gradients to zero"
      ],
      "metadata": {
        "id": "XArjV53J7MP5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bPo8xLeH7Pbc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}