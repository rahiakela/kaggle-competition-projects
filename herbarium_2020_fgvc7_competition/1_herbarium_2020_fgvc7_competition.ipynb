{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-herbarium-2020-fgvc7-competition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/kaggle-competition-projects/blob/herbarium-2020-fgvc7-competition/1_herbarium_2020_fgvc7_competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0cRws4ek4Wc",
        "colab_type": "text"
      },
      "source": [
        "# Herbarium 2020 - FGVC7\n",
        "**Identify plant species from herbarium specimens. Data from New York Botanical Garden.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yMRCCsik-F2",
        "colab_type": "text"
      },
      "source": [
        "The Herbarium 2020 FGVC7 Challenge is to identify vascular plant species from a large, long-tailed collection herbarium specimens provided by the [New York Botanical Garden](https://www.nybg.org/plant-research-and-conservation/) (NYBG).\n",
        "\n",
        "The Herbarium 2020 dataset contains over 1M images representing over 32,000 plant species. This is a dataset with a long tail; there are a minimum of 3 specimens per species, however, some species are represented by more than a hundred specimens. This dataset only contains vascular land plants which includes lycophytes, ferns, gymnosperms, and flowering plants. The extinct forms of lycophytes are the major component of coal deposits, ferns are indicators of ecosystem health, gymnosperms provide major habitats for animals, and flowering plants provide all of our crops, vegetables, and fruits.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/herbarium.png?raw=1' width='800'/>\n",
        "\n",
        "The teams with the most accurate models will be contacted, with the intention of using them on the un-named plant collections in the NYBG herbarium collection, and assessed by the NYBG plant specialists.\n",
        "\n",
        "Reference:\n",
        "\n",
        "https://www.kaggle.com/rsingh99/getting-started-with-herbarium-2020\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Q_MgU3rpog",
        "colab_type": "text"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIGUB-A0rr0E",
        "colab_type": "text"
      },
      "source": [
        "The New York Botanical Garden (NYBG) herbarium contains more than 7.8 million plant and fungal specimens. Herbaria are a massive repository of plant diversity data. These collections not only represent a vast amount of plant diversity, but since herbarium collections include specimens dating back hundreds of years, they provide snapshots of plant diversity through time. The integrity of the plant is maintained in herbaria as a pressed, dried specimen; a specimen collected nearly two hundred years ago by Darwin looks much the same as one collected a month ago by an NYBG botanist. All specimens not only maintain their morphological features but also include collection dates and locations, and the name of the person who collected the specimen. This information, multiplied by millions of plant collections, provides the framework for understanding plant diversity on a massive scale and learning how it has changed over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IvDDh5NlhFl",
        "colab_type": "text"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Asov85lh_4",
        "colab_type": "text"
      },
      "source": [
        "The training and test set contain images of herbarium specimens, from over 32,000 species of vascular plants. Each image contains exactly one specimen. The text and barcode labels on the specimen images have been blurred to remove category information in the image.\n",
        "\n",
        "The data has been approximately split 80%/20% for training/test. Each category has at least 1 instance in both the training and test datasets. Note that the test set distribution is slightly different from the training set distribution. The training set contains species with hundreds of examples, but the test set has the number of examples per species capped at a maximum of 10.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLQ51bYTr5fP",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB1sd9bBr6w2",
        "colab_type": "text"
      },
      "source": [
        "Each image has different image dimensions, with a maximum of 1000 pixels in the larger dimension. These have been resized from the original image resolution. All images are in JPEG format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk5tzwwgr-Sm",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVgyqxLasAuy",
        "colab_type": "text"
      },
      "source": [
        "This dataset uses the [COCO dataset format](http://cocodataset.org/#format-data) with additional annotation fields. In addition to the species category labels, we also provide region and supercategory information.\n",
        "\n",
        "The training set metadata (train/metadata.json) and test set metadata (test/metadata.json) are JSON files in the format below. Naturally, the test set metadata file omits the \"annotations\", \"categories\" and \"regions\" elements.\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"annotations\" : [annotation],\n",
        "  \"categories\" : [category],\n",
        "  \"images\" : [image],\n",
        "  \"info\" : info,\n",
        "  \"licenses\": [license],\n",
        "  \"regions\": [region]\n",
        "}\n",
        "\n",
        "info {\n",
        "  \"year\" : int,\n",
        "  \"version\" : str,\n",
        "  \"url\": str,\n",
        "  \"description\" : str,\n",
        "  \"contributor\" : str,\n",
        "  \"date_created\" : datetime\n",
        "}\n",
        "\n",
        "image {\n",
        "  \"id\" : int,\n",
        "  \"width\" : int,\n",
        "  \"height\" : int,\n",
        "  \"file_name\" : str,\n",
        "  \"license\" : int\n",
        "}\n",
        "\n",
        "annotation {\n",
        "  \"id\": int,\n",
        "  \"image_id\": int,\n",
        "  \"category_id\": int,\n",
        "  # Region where this specimen was collected.\n",
        "  \"region_id\": int\n",
        "}\n",
        "\n",
        "category {\n",
        "  \"id\" : int,\n",
        "  # Species name\n",
        "  \"name\" : str,\n",
        "  # We also provide the super-categories for each species.\n",
        "  \"family\": str,\n",
        "  \"genus\": str\n",
        "}\n",
        "\n",
        "region {\n",
        "  \"id\": int\n",
        "  \"name\": str\n",
        "}\n",
        "\n",
        "license {\n",
        "  \"id\": 1,\n",
        "  \"name\": str,\n",
        "  \"url\": str\n",
        "}\n",
        "```\n",
        "\n",
        "The training set images are organized in subfolders:\n",
        "```python \n",
        "train/<subfolder1>/<subfolder2>/<image id>.jpg\n",
        "```\n",
        "\n",
        "The test set images are organized in subfolders:\n",
        "```python\n",
        "test/<subfolder>/<image id>.jpg\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODoqgXITlx82",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoYZdPYBlzTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8syoIN9imffF",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of877uXembD7",
        "colab_type": "code",
        "outputId": "b9cc0632-0bd7-4c96-9f6f-95448adceb3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "!kaggle -v"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: kaggle 1.5.6\n",
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\n",
            "Processing /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01/kaggle-1.5.6-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2019.11.28)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.8)\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Kaggle API 1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heEVwOn9muF2",
        "colab_type": "text"
      },
      "source": [
        "First of all, needs to copy kaggle.json file to .kaggle directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtBs1o-Qmp2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy kaggle.json file to .kaggle directory\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyh0X35sm6ON",
        "colab_type": "code",
        "outputId": "098cd1cc-9e8a-419d-8ff9-bda88edfb350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "# show all availabe datasets\n",
        "!kaggle datasets list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                                         title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "unanimad/dataisbeautiful                                    Reddit - Data is Beautiful                           11MB  2020-03-21 22:28:28            443         49  1.0              \n",
            "allen-institute-for-ai/CORD-19-research-challenge           COVID-19 Open Research Dataset Challenge (CORD-19)  646MB  2020-03-20 23:31:34          22457       3252  0.88235295       \n",
            "rubenssjr/brasilian-houses-to-rent                          brazilian_houses_to_rent                            117KB  2020-03-15 01:12:22            488         27  1.0              \n",
            "sudalairajkumar/novel-corona-virus-2019-dataset             Novel Corona Virus 2019 Dataset                     384KB  2020-03-22 10:37:50          68954       2751  0.9705882        \n",
            "kimjihoo/coronavirusdataset                                 Data Science for COVID-19 (DS4C)                      3MB  2020-03-22 04:17:54          18829        757  1.0              \n",
            "jessemostipak/hotel-booking-demand                          Hotel booking demand                                  1MB  2020-02-13 01:27:20           9686        411  1.0              \n",
            "shivamb/real-or-fake-fake-jobposting-prediction             [Real or Fake] Fake JobPosting Prediction            16MB  2020-02-29 08:23:34           1944        127  1.0              \n",
            "brunotly/foreign-exchange-rates-per-dollar-20002019         Foreign Exchange Rates 2000-2019                      1MB  2020-03-03 17:43:07           1501         69  1.0              \n",
            "timoboz/data-science-cheat-sheets                           Data Science Cheat Sheets                           596MB  2020-02-04 19:42:27           5892        370  0.875            \n",
            "imdevskp/ebola-outbreak-20142016-complete-dataset           Ebola 2014-2016 Outbreak Complete Dataset           101KB  2020-02-26 14:36:31           1727         76  1.0              \n",
            "imdevskp/sars-outbreak-2003-complete-dataset                SARS 2003 Outbreak Complete Dataset                  10KB  2020-02-26 10:25:22           1778         70  1.0              \n",
            "tunguz/big-five-personality-test                            Big Five Personality Test                           159MB  2020-02-17 15:59:37           2966        217  0.9705882        \n",
            "brendaso/2019-coronavirus-dataset-01212020-01262020         2019 Coronavirus dataset (January - February 2020)   53KB  2020-02-06 18:09:28           9322        451  0.7352941        \n",
            "jamzing/sars-coronavirus-accession                          SARS CORONAVIRUS ACCESSION                            2MB  2020-02-18 15:49:34           2475        131  0.9411765        \n",
            "paultimothymooney/coronavirus-genome-sequence               Coronavirus Genome Sequence                           9MB  2020-02-29 00:25:13            489         40  1.0              \n",
            "timoboz/tesla-stock-data-from-2010-to-2020                  Tesla stock data from 2010 to 2020                   46KB  2020-02-04 17:15:32           2881        117  1.0              \n",
            "prakrutchauhan/indian-candidates-for-general-election-2019  Indian Candidates for General Election 2019         133KB  2020-03-03 07:01:53            931         45  0.7058824        \n",
            "timoboz/python-data-science-handbook                        Python Data Science Handbook                         15MB  2020-02-04 18:27:14           1395        180  0.88235295       \n",
            "gpiosenka/100-bird-species                                  150 Bird Species                                    946MB  2020-03-15 23:17:43            900         72  0.6875           \n",
            "timoboz/google-trends-data                                  Google Trends Data                                    1MB  2020-02-04 17:31:10           2951        149  0.9117647        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK09aPaZmxOF",
        "colab_type": "code",
        "outputId": "3406707c-c076-4ca1-f194-00c97426309d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Try to downlaod data for the herbarium-2020-fgvc7 challenge.\n",
        "!kaggle competitions download -c herbarium-2020-fgvc7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading covid19-global-forecasting-week-1.zip to /content\n",
            "\r  0% 0.00/195k [00:00<?, ?B/s]\n",
            "\r100% 195k/195k [00:00<00:00, 89.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huv7wqkfnWg5",
        "colab_type": "text"
      },
      "source": [
        "### Unzip dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ovkFFNnEOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "import zipfile\n",
        "\n",
        "# path to the directory where the original dataset was uncompressed\n",
        "original_dataset_dir = 'kaggle_herbarium_2020_fgvc7'\n",
        "\n",
        "# remove directories if it already exists\n",
        "shutil.rmtree(original_dataset_dir, ignore_errors=True)\n",
        "\n",
        "# create directories\n",
        "os.mkdir(original_dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OTOuGD6ncrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip dataset\n",
        "with zipfile.ZipFile(\"herbarium-2020-fgvc7.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(original_dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzBT1fqmLuq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN       = \"../input/herbarium-2020-fgvc7/nybg2020/train/\"\n",
        "TEST        = \"../input/herbarium-2020-fgvc7/nybg2020/test/\"\n",
        "META        = \"metadata.json\"\n",
        "BATCH_SIZE  = 7\n",
        "NUM_WORKERS = 2\n",
        "BATCH_EVAL  = 1\n",
        "SHUFFLE     = True\n",
        "EPOCHS      = 3\n",
        "RESIZE      = (800, 600)\n",
        "CLASSES     = 32094\n",
        "LENGTH      = 2*CLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKFaRsRzpse1",
        "colab_type": "text"
      },
      "source": [
        "## DATA INSIGTH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jet1H6gDLF3h",
        "colab_type": "text"
      },
      "source": [
        "The dataset is in COCO Format.\n",
        "\n",
        "COCO is a large image dataset designed for object detection, segmentation, person keypoints detection, stuff segmentation, and caption generation. This package provides Matlab, Python, and Lua APIs that assists in loading, parsing, and visualizing the annotations in COCO. Please visit http://cocodataset.org/ for more information on COCO, including for the data, paper, and tutorials. The exact format of the annotations is also described on the COCO website. The Matlab and Python APIs are complete, the Lua API provides only basic functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLzIyte3ptYs",
        "colab_type": "text"
      },
      "source": [
        "### Train file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbDim7T9o7sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(join(TRAIN, META), 'r', encoding='ISO-8859-1') as file:\n",
        "  metadata = json.load(file)\n",
        "  print('Metadata has {} sections'.format(len(list(metadata.keys()))))\n",
        "  print('All the sections in metadata:\\n', [print(' - ', i) for i in list(metadata.keys())])\n",
        "\n",
        "  print('Number of Images in Training set is:- ', len(metadata['images']))\n",
        "  print('\\nLet us see how every section of Dataset Looks like:-\\n')\n",
        "  for i in list(metadata.keys()):\n",
        "    print(' - sample and number of elements in {} :- '.format(i), len(list(metadata[i])))\n",
        "    print('\\t', list(metadata[i])[0], end='\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9bIO48ZOn1V",
        "colab_type": "text"
      },
      "source": [
        "### Test file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKgmh96IsMCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(join(TEST, META), 'r', encoding='ISO-8859-1') as file:\n",
        "  metadata_test = json.load(file)\n",
        "  print('Metadata has {} sections'.format(len(list(metadata_test.keys()))))\n",
        "  print('All the sections in metadata:\\n', [print(' - ', i) for i in list(metadata_test.keys())])\n",
        "\n",
        "  print('Number of Images in Test set is:- ', len(metadata_test['images']))\n",
        "  print('\\nLet us see how every section of Dataset Looks like:-\\n')\n",
        "  for i in list(metadata_test.keys()):\n",
        "    print(' - sample and number of elements in {} :- '.format(i), len(list(metadata_test[i])))\n",
        "    print('\\t', list(metadata_test[i])[0], end='\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKEEONjW39od",
        "colab_type": "text"
      },
      "source": [
        "There are 1030747 Images in Train set.\n",
        "\n",
        "There are 32094 Classes in The dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMIXTXg_PlWx",
        "colab_type": "text"
      },
      "source": [
        "### Visulize some image sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zim04ZkAPoDn",
        "colab_type": "text"
      },
      "source": [
        "Now let us see the Image Sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ijEwSikPdnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img = pd.DataFrame(metadata['images'])\n",
        "train_ann = pd.DataFrame(metadata['annotations'])\n",
        "train_df = pd.merge(train_img, train_ann, left_on='image_id', right_on='id', how='left').drop('image_id', axis=1).sort_values(by=['category_id'])\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0zEf2IbQzQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = Image.open('herbarium-2020-fgvc7/nybg2020/train/images/156/72/354106.jpg')\n",
        "print('Category Id is 15672 and Image Id is 354106 is shown below.')\n",
        "img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv_ysBrk4JD6",
        "colab_type": "text"
      },
      "source": [
        "### Data Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7AAn-7iRNgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = (28, 28)\n",
        "\n",
        "fig = plt.figure(figsize=(72, 72))\n",
        "for i in range(60):\n",
        "  ax = fig.add_subplot(12, 12, i + 1)\n",
        "  img = cv2.imread(TRAIN + metadata['images'][i]['file_name'])\n",
        "  img = cv2.resize(img, img_size)\n",
        "  ax.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwuJNA7T4KtJ",
        "colab_type": "text"
      },
      "source": [
        "## DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ME6waVX3a-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}