{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-exploratory-data-analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOss4IAM37lxft9ug2q7Hsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/kaggle-competition-projects/blob/master/google-ai4code/01_exploratory_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Google AI4Code: Exploratory Data Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "fxjJ9XCzkCA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory data analysis is the work of a detective. Understanding the possibilities of your data is the first step in laying the groundwork for future modeling. With this notebook, we try to make sense of our data and demonstrate how data can be analyzed. We'll look for trends, limitations, and other characteristics linked to the questions we're interested in as part of our investigation.**\n",
        "\n",
        "Reference:\n",
        "\n",
        "https://www.kaggle.com/code/andreaspalmgren/ai4code-comprehensive-eda"
      ],
      "metadata": {
        "id": "3Y41yF4xnk6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "okE9A7denwVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import re\n",
        "import os\n",
        "\n",
        "pd.options.display.width = 180\n",
        "pd.options.display.max_colwidth = 100\n",
        "\n",
        "data_dir = Path(\"../input/AI4Code\")\n",
        "\n",
        "rc = {\"axes.spines.left\" : True,\n",
        "      \"axes.spines.right\" : False,\n",
        "      \"axes.spines.bottom\" : True,\n",
        "      \"axes.spines.top\" : False,\n",
        "      \"xtick.bottom\" : True,\n",
        "      \"xtick.labelbottom\" : True,\n",
        "      \"ytick.labelleft\" : True,\n",
        "      \"ytick.left\" : True,\n",
        "      \"figure.subplot.hspace\" : 0.7,\n",
        "    \"figure.titleweight\" : \"bold\",\n",
        "    \"axes.titleweight\" : \"bold\",\n",
        "     \"font.weight\" : \"bold\"}\n",
        "plt.rcParams.update(rc)"
      ],
      "metadata": {
        "id": "JsIsiP9Nnz0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x66e8lWQkPlF",
        "outputId": "1be5ee96-b478-4ff3-a376-cd52ed550ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# content/gdrive/My Drive/Kaggle is the path where kaggle.json is  present in the Google Drive\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle-keys\""
      ],
      "metadata": {
        "id": "iHwuEGvgkT5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# download dataset from kaggle> URL: https://www.kaggle.com/competitions/AI4Code\n",
        "kaggle competitions download -c AI4Code\n",
        "\n",
        "unzip -qq AI4Code.zip\n",
        "rm -rf AI4Code.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaL8UZePkaBM",
        "outputId": "24aceee7-c9e6-4402-8e1f-029784ec99e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading AI4Code.zip to /content\n",
            " 97% 694M/714M [00:05<00:00, 171MB/s]\n",
            "100% 714M/714M [00:05<00:00, 141MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data source"
      ],
      "metadata": {
        "id": "s8723NZeoLgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google and X, the moonshot factory, have supplied the dataset, which contains about 160 000 Jupyter notebooks. This is part of a <a href=\"https://www.kaggle.com/competitions/AI4Code\">Kaggle competition</a> to train a model that can rank markdown cells depending on the order of its code cells. \n",
        "\n",
        "Code cells are written in python and markdown cells are written in markdown, which is the text formatting langague used in Jupyter.**"
      ],
      "metadata": {
        "id": "TdhODbP7oT55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_notebook(path):\n",
        "  return (\n",
        "      pd.read_json(path, dtype={\"cell_type\": \"category\", \"source\": \"str\"})\n",
        "        .assign(id=path.stem)\n",
        "        .rename_axis(\"cell_id\")\n",
        "  )"
      ],
      "metadata": {
        "id": "-NKze0qHoUYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset of training due to its large size\n",
        "NUM_TRAIN = 20000\n",
        "\n",
        "paths_train = list((\"train\").glob(\"*.json\"))[:NUM_TRAIN]\n",
        "\n",
        "notebooks_train = [read_notebook(path) for path in tqdm(paths_train, desc=\"Train NBs\")]\n",
        "# Get notebooks\n",
        "df_notebooks = (pd.concat())"
      ],
      "metadata": {
        "id": "gBehB5zBpMuF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}